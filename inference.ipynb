{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_lang = \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# inference_df = pd.read_csv(f\"language_wise/{csv_lang}_intro.csv\")\n",
    "inference_df = pd.read_csv(\"user_study/hi_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_df = inference_df.drop_duplicates(subset=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hi_intro                                 100\n",
       "en_categories                            100\n",
       "title                                    100\n",
       "language                                 100\n",
       "link                                     100\n",
       "Age Group                                 97\n",
       "Caste                                     30\n",
       "Count                                     97\n",
       "Highest Educational Qualification         31\n",
       "Era                                       97\n",
       "Ethnicity                                 97\n",
       "Entity Existence Type                     97\n",
       "Fame                                      97\n",
       "Gender                                    97\n",
       "Life Status                               97\n",
       "Nationality                               97\n",
       "Origin-of-Culture                         97\n",
       "Religion                                  33\n",
       "Role                                      34\n",
       "Sex                                       34\n",
       "Sexual Orientation                        34\n",
       "Pronoun/Verb in Article Text             100\n",
       "Pronoun/Verb Usage in Written Context    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inference_df) - inference_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_df = inference_df.drop([\"en_categories\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Unnamed: 0'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[221], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# inference_df = inference_df.drop([\"bpy\", \"bpy_intro\"], axis=1)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inference_df \u001b[38;5;241m=\u001b[39m \u001b[43minference_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnnamed: 0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Unnamed: 0'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# inference_df = inference_df.drop([\"bpy\", \"bpy_intro\"], axis=1)\n",
    "inference_df = inference_df.drop(columns=[\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hi_intro                                 100\n",
       "en_categories                            100\n",
       "title                                    100\n",
       "language                                 100\n",
       "link                                     100\n",
       "Age Group                                 97\n",
       "Caste                                     30\n",
       "Count                                     97\n",
       "Highest Educational Qualification         31\n",
       "Era                                       97\n",
       "Ethnicity                                 97\n",
       "Entity Existence Type                     97\n",
       "Fame                                      97\n",
       "Gender                                    97\n",
       "Life Status                               97\n",
       "Nationality                               97\n",
       "Origin-of-Culture                         97\n",
       "Religion                                  33\n",
       "Role                                      34\n",
       "Sex                                       34\n",
       "Sexual Orientation                        34\n",
       "Pronoun/Verb in Article Text             100\n",
       "Pronoun/Verb Usage in Written Context    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inference_df) - inference_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # non_null = inference_df.dropna()\n",
    "\n",
    "# # print(len(non_null))\n",
    "# inference_df = inference_df.iloc[:30]\n",
    "# inference_df = inference_df[inference_df[\"title\"].__eq__(\"Chandrayee Ghosh\")]\n",
    "# inference_df = inference_df[inference_df[\"human\"].__eq__(\"http://www.wikidata.org/entity/Q890911\")]\n",
    "# # non_null = inference_df[~inference_df[\"bpy_intro\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             hi_intro  \\\n",
      "0   ऋषि सुनक (जन्म 12 मई 1980) भारतीय मूल के ब्रिट...   \n",
      "1   विद्या देवी भंडारी (नेपाली: विद्यादेवी भण्डारी...   \n",
      "2   ग्रेटा थनबर्ग (ग्रेटा टिनटिन एलोनोरा एर्नमन थन...   \n",
      "3   दुर्गा या आदिशक्ति हिन्दुओं की प्रमुख देवी मान...   \n",
      "4   सरस्वती हिन्दू धर्म की प्रमुख वैदिक एवं पौराणि...   \n",
      "..                                                ...   \n",
      "95  मैडोना (मैडोना लुईस चिकोने जन्म, 16 अगस्त 1958...   \n",
      "96  व्लदिमिर इल्यिच उल्यानोव, जिन्हें लेनिन के नाम...   \n",
      "97  शकुनि या शकुनी गंधार साम्राज्य का राजा था। यह ...   \n",
      "98  जटायु रामायण के एक प्रसिद्ध गरुड़ पात्र है। जब...   \n",
      "99  दाउद इब्राहिम कासकर एक कुख्यात आतंकवादी है जो ...   \n",
      "\n",
      "                                        en_categories                title  \\\n",
      "0   Category:1980 births|Category:21st-century pri...          Rishi Sunak   \n",
      "1   Category:1961 births|Category:21st-century Nep...  Bidya Devi Bhandari   \n",
      "2   Category:2003 births|Category:21st-century Swe...       Greta Thunberg   \n",
      "3   Category:All articles with unsourced statement...                Durga   \n",
      "4   Category:All articles covered by WikiProject W...            Saraswati   \n",
      "..                                                ...                  ...   \n",
      "95  Category:1958 births|Category:20th-century Ame...              Madonna   \n",
      "96  Category:1870 births|Category:1924 deaths|Cate...       Vladimir Lenin   \n",
      "97  Category:All Wikipedia articles written in Ind...              Shakuni   \n",
      "98  Category:All Wikipedia articles written in Ind...               Jatayu   \n",
      "99  Category:1955 births|Category:1993 Bombay bomb...       Dawood Ibrahim   \n",
      "\n",
      "   language                                               link Age Group  \\\n",
      "0     Hindi  https://hi.wikipedia.org/wiki/%E0%A4%8B%E0%A4%...     Adult   \n",
      "1     Hindi  https://hi.wikipedia.org/wiki/%E0%A4%B5%E0%A4%...       Old   \n",
      "2     Hindi  https://hi.wikipedia.org/wiki/%E0%A4%97%E0%A5%...     Adult   \n",
      "3     Hindi  https://hi.wikipedia.org/wiki/%E0%A4%A6%E0%A5%...     Adult   \n",
      "4     Hindi  https://hi.wikipedia.org/wiki/%E0%A4%B8%E0%A4%...     Adult   \n",
      "..      ...                                                ...       ...   \n",
      "95    Hindi  https://hi.wikipedia.org/wiki/%E0%A4%AE%E0%A5%...       Old   \n",
      "96    Hindi  https://hi.wikipedia.org/wiki/%E0%A4%B5%E0%A5%...       Old   \n",
      "97    Hindi                https://hi.wikipedia.org/wiki/शकुनी       NaN   \n",
      "98    Hindi                https://hi.wikipedia.org/wiki/जटायु       NaN   \n",
      "99    Hindi        https://hi.wikipedia.org/wiki/दाऊद_इब्राहिम       NaN   \n",
      "\n",
      "                             Caste     Count  \\\n",
      "0          Warrior and Ruler Class  Singular   \n",
      "1          Warrior and Ruler Class  Singular   \n",
      "2                   Not Applicable  Singular   \n",
      "3   Religious and Priesthood Class  Singular   \n",
      "4   Religious and Priesthood Class  Singular   \n",
      "..                             ...       ...   \n",
      "95                             NaN  Singular   \n",
      "96                             NaN  Singular   \n",
      "97                             NaN       NaN   \n",
      "98                             NaN       NaN   \n",
      "99                             NaN       NaN   \n",
      "\n",
      "   Highest Educational Qualification         Era  ...      Gender  \\\n",
      "0                       Postgraduate      Modern  ...     Boy/Man   \n",
      "1                      Undergraduate      Modern  ...  Girl/Woman   \n",
      "2                          Secondary      Modern  ...  Girl/Woman   \n",
      "3                            Unknown  Historical  ...  Girl/Woman   \n",
      "4                            Unknown  Historical  ...  Girl/Woman   \n",
      "..                               ...         ...  ...         ...   \n",
      "95                               NaN      Modern  ...  Girl/Woman   \n",
      "96                               NaN      Modern  ...     Boy/Man   \n",
      "97                               NaN         NaN  ...         NaN   \n",
      "98                               NaN         NaN  ...         NaN   \n",
      "99                               NaN         NaN  ...         NaN   \n",
      "\n",
      "       Life Status     Nationality Origin-of-Culture      Religion  \\\n",
      "0            Alive  United Kingdom            Exotic       Sikhism   \n",
      "1            Alive           Nepal            Exotic      Hinduism   \n",
      "2            Alive          Sweden            Exotic  Christianity   \n",
      "3   Not Applicable           India            Native      Hinduism   \n",
      "4   Not Applicable           India            Native      Hinduism   \n",
      "..             ...             ...               ...           ...   \n",
      "95           Alive   United States            Exotic           NaN   \n",
      "96            Dead          Russia            Exotic           NaN   \n",
      "97             NaN             NaN               NaN           NaN   \n",
      "98             NaN             NaN               NaN           NaN   \n",
      "99             NaN             NaN               NaN           NaN   \n",
      "\n",
      "                       Role     Sex Sexual Orientation  \\\n",
      "0   Politics and Governance    Male       Heterosexual   \n",
      "1   Politics and Governance  Female       Heterosexual   \n",
      "2   Activists and Reformers  Female            Unknown   \n",
      "3                     Deity  Female       Heterosexual   \n",
      "4                     Deity  Female       Heterosexual   \n",
      "..                      ...     ...                ...   \n",
      "95                      NaN     NaN                NaN   \n",
      "96                      NaN     NaN                NaN   \n",
      "97                      NaN     NaN                NaN   \n",
      "98                      NaN     NaN                NaN   \n",
      "99                      NaN     NaN                NaN   \n",
      "\n",
      "   Pronoun/Verb in Article Text Pronoun/Verb Usage in Written Context  \n",
      "0                     Honorific                             Honorific  \n",
      "1                     Honorific                             Honorific  \n",
      "2                     Honorific                             Honorific  \n",
      "3                     Honorific                             Honorific  \n",
      "4                     Honorific                             Honorific  \n",
      "..                          ...                                   ...  \n",
      "95                Non-Honorific                             Honorific  \n",
      "96                    Honorific                             Honorific  \n",
      "97                Non-Honorific                         Non-Honorific  \n",
      "98                    Honorific                         Non-Honorific  \n",
      "99                Non-Honorific                         Non-Honorific  \n",
      "\n",
      "[100 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(inference_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# USER_AGENT = \"WikiIntroExtractor/1.0 (Sourabarata Mukherjee; soura1990@gmail.com)\"\n",
    "\n",
    "# def get_introductory_text(wiki_url):\n",
    "#     if not wiki_url or wiki_url is None:\n",
    "#         return None\n",
    "#     try:\n",
    "#         # Extract the title from the URL\n",
    "#         encoded_title = wiki_url.split(\"/\")[-1]\n",
    "#         title = requests.utils.unquote(encoded_title)\n",
    "        \n",
    "#         # API endpoint and parameters\n",
    "#         api_url = f\"https://{wiki_url.split('/')[2]}/w/api.php\"\n",
    "#         params = {\n",
    "#             \"action\": \"query\",\n",
    "#             \"format\": \"json\",\n",
    "#             \"prop\": \"extracts\",\n",
    "#             \"explaintext\": True,\n",
    "#             \"titles\": title\n",
    "#         }\n",
    "#         headers = {\"User-Agent\": USER_AGENT}\n",
    "        \n",
    "#         # Make the API request\n",
    "#         response = requests.get(api_url, headers=headers, params=params, timeout=60)\n",
    "#         if response.status_code != 200:\n",
    "#             print(response)\n",
    "#             return None\n",
    "#         data = response.json()\n",
    "#         pages = data.get(\"query\", {}).get(\"pages\", {})\n",
    "#         page = next(iter(pages.values()))\n",
    "#         intro = page.get(\"extract\", None)\n",
    "        \n",
    "#         if intro == \"\":\n",
    "#             return None\n",
    "        \n",
    "#         return intro\n",
    "#     except Exception as e:\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = get_introductory_text(non_null[\"hi\"].iloc[0])\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pd.option_context(\"display.max_rows\", 100, \"display.max_columns\", 200) : \n",
    "#     print(non_null.isna())\n",
    "#     print(non_null[\"hi_intro\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def postprocess(input_data):\n",
    "    # Extract content inside the first { } using regex\n",
    "    match = re.search(r'\\{[\\s\\S]*\\}', input_data)  # Ensures capturing nested JSON structures\n",
    "    \n",
    "    if not match:\n",
    "        raise ValueError(\"No valid JSON-like dictionary found in the input.\")\n",
    "\n",
    "    valid_json_str = match.group(0)\n",
    "\n",
    "    # Step 1: Ensure proper JSON formatting\n",
    "    valid_json_str = valid_json_str.replace(\"'\", '\"')  # Convert single quotes to double quotes\n",
    "\n",
    "    # Step 2: Remove trailing commas (which are invalid in JSON)\n",
    "    valid_json_str = re.sub(r',\\s*([\\]}])', r'\\1', valid_json_str)\n",
    "\n",
    "    try:\n",
    "        # Step 3: Load as a Python dictionary\n",
    "        data = json.loads(valid_json_str)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"JSON Decode Error:\", str(e))\n",
    "        print(\"Problematic JSON String:\", valid_json_str)  # Debugging output\n",
    "        raise  # Rethrow exception after printing\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !pip install tiktoken\n",
    "# !pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import openai\n",
    "import json\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import os \n",
    "import tiktoken\n",
    "import anthropic\n",
    "\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "\n",
    "# client = anthropic.Anthropic(\n",
    "#     # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    "#     api_key=ANTHROPIC_KEY,\n",
    "# )\n",
    "\n",
    "# # print(message.content)\n",
    "\n",
    "     \n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "# encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "# encoding = tiktoken.encoding_for_model(\"GPT-4o-mini Global Deployment\")\n",
    "\n",
    "## Fill credentials here\n",
    "api_key = os.getenv(\"AZURE_OPENAI_KEY\", \"\")\n",
    "endpoint = os.getenv(\"ENDPOINT_URL\", \"\")\n",
    "# deployment = os.getenv(\"DEPLOYMENT_NAME\", \"gpt35turbo\")\n",
    "\n",
    "# Define deployment names for o1 and gpt-4o models\n",
    "deployment_o1 = os.getenv(\"DEPLOYMENT_NAME_O1\", \"o1\")\n",
    "deployment_4o = os.getenv(\"DEPLOYMENT_NAME_4O\", \"gpt-4o\")\n",
    "deployment_4o_mini = os.getenv(\"DEPLOYMENT_NAME_4O_MINI\", \"gpt-4o-mini\")\n",
    "deployment_sonar = os.getenv(\"DEPLOYMENT_NAME_SONAR\", \"sonar-pro\")\n",
    "deployment_o1_mini = os.getenv(\"DEPLOYMENT_NAME_O1_MINI\", \"o1-mini\")\n",
    "\n",
    "\n",
    "# Initialize the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=endpoint,\n",
    "    api_key=api_key,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    ")\n",
    "\n",
    "# client = OpenAI(api_key=api_key, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "pronouns = \"\"\"Examples of Honorific Pronouns: \"वे\", \"उनका\", \"उनके \", \"उनको\", \"उन्होंने\", \"उन्हें\", \"उनसे\", \"इनका\", \"इनकɃ\", \"इनके \", \"इनको\"\n",
    "Examples of Non-Honorific Pronouns: \"वह\", \"वो\", \"उसने\", \"उसको\", \"उसे\", \"उसका\", \"उसके \", \"उसकɃ\", \"उनका\", \"उनके \", \"उनकɃ\", \"उनको\", \"इसका\", \"इसकɃ\", \"इसके \", \"इनका\", \"इनकɃ\", \"इनके \", \"इनको\", \"उनसे\", \"उन्होंने\", \"उन्हें\"\n",
    "\"\"\"\n",
    "\n",
    "verbs = \"\"\"Examples of Honorific Verbs: \"उन्होंने किया\", \"उन्होंने कहा\", \"करते हैं\", \"मिलीं\", \"थे\"\n",
    "Examples of Non-Honorific Verbs: \"उसने किया\", \"उसने कहा\", \"करता है\", \"मिली\", \"था\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# pronouns = \"\"\"- Examples of Honorific Pronouns: \"তিনি\", \"তাঁরা\", \"তাঁর\", \"তাঁদের\", \"ইনি\", \"উনি\", \"ওঁনারা\", \"যিনি\"\n",
    "#         - Examples of Non-Honorific Pronouns: \"সে\", \"ও\", \"ওরা\", \"তারা\", \"তার\", \"ওর\", \"তাদের\", \"ওদের\"\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# verbs = \"\"\"- Examples of Honorific Verbs: \"যান\", \"বলেন\", \"লেখেন\", \"করেছেন\", \"বলেছেন\", \"দেখেছেন\", \"শুনেছেন\", \"লিখেছেন\", \"করবেন\", \"লিখবেন\", \"করছেন\"\n",
    "#         - Examples of Non-Honorific Verbs: \"যায়\", \"বলে\", \"লেখে\", \"করেছে\", \"বলেছে\", \"দেখেছে\", \"শুনেছে\", \"লিখেছে\", \"করবে\", \"লিখবে\"\n",
    "# \"\"\"\n",
    "# pronouns = \"\"\n",
    "# verbs = \"\"\n",
    "\n",
    "if pronouns != \"\" or verbs != \"\" : \n",
    "    examples = f\"\"\"Examples: \n",
    "        {pronouns}\n",
    "        {verbs}\n",
    "    \"\"\"\n",
    "    \n",
    "else : \n",
    "    examples = \"\"\n",
    "\n",
    "def generate_output(title, article_text, en_categories, lang_categories, language, model_type=\"o1\"):\n",
    "    # Choose the appropriate deployment name\n",
    "    if \"gpt-4o\" in model_type.lower():\n",
    "        # print(\"Using gpt-4o\")\n",
    "        deployment = deployment_4o\n",
    "    elif model_type == \"o1\":\n",
    "        deployment = deployment_o1  # Default to o1 model\n",
    "        \n",
    "    elif model_type == \"gpt-4o-mini\": \n",
    "        deployment = deployment_4o_mini\n",
    "        \n",
    "    elif model_type == \"sonar-pro\" : \n",
    "        deployment = deployment_sonar\n",
    "        \n",
    "    elif model_type == \"o1-mini\": \n",
    "        deployment = deployment_o1_mini\n",
    "        \n",
    "    else : \n",
    "        deployment = model_type\n",
    "        \n",
    "    messages=[\n",
    "        {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You will be provided with statements, and your task is to convert them to standard English.\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"\"\"We need your help to specify the usage of third-person honorific and non-honorific pronouns, and/or verbs in the {language} article text titled {title}.\n",
    "        \n",
    "        {examples}\n",
    "        \n",
    "        Article Text:\n",
    "\n",
    "        {article_text}\n",
    "        \n",
    "        Categories in English:\n",
    "\n",
    "        {en_categories}\n",
    "        \n",
    "        \n",
    "        Task:\n",
    "\n",
    "        Please carefully review the article text, categories, and select the value for the following features for the article:\n",
    "\n",
    "        - Age Group: \n",
    "            - Adult (18-60)\n",
    "            - Juvenile (under 18)\n",
    "            - Old (60+)\n",
    "            - Not Applicable (for abstract entities like concepts or gods)\n",
    "\n",
    "        - Caste (if applicable): \n",
    "            - Labor and Service Class: Includes workers, servants, and manual laborers (e.g., Shudras in Hinduism, serfs in feudal Europe).\n",
    "            - Marginalized Groups: Includes historically excluded or oppressed groups (e.g., Dalits in India, Burakumin in Japan, untouchables in other societies).\n",
    "            - Merchant and Artisan Class: Includes traders, craftsmen, and business people (e.g., Vaishyas in Hinduism, merchant guilds in medieval Europe, bazaar merchants in Islamic societies).\n",
    "            - Religious and Priesthood Class: Includes clergy, priests, and spiritual leaders (e.g., Brahmins in Hinduism, clergy in Christianity, imams in Islam).\n",
    "            - Warrior and Ruler Class: Includes nobility, royalty, and military elites (e.g., Kshatriyas in Hinduism, samurai in Japan, knights in medieval Europe).\n",
    "            - Not Applicable (if none apply, e.g., abstract entities, non-human beings, deities, or supernatural beings)\n",
    "\n",
    "        - Count: \n",
    "            - Plural (group or category)\n",
    "            - Singular (individual entity)\n",
    "            - Not Applicable (abstract concepts, mixed subjects)\n",
    "\n",
    "        - Highest Educational Qualification: Each category represents the highest level of education an individual or entity has completed.\n",
    "            - Doctoral: Holds a Doctorate (Ph.D. or equivalent) from an accredited institution.\n",
    "            - Elementary: Has completed primary education, which typically covers early schooling years before secondary education.\n",
    "            - Postgraduate: Completed a Master’s degree or equivalent postgraduate qualification.\n",
    "            - Secondary: Completed secondary education, typically equivalent to high school.\n",
    "            - Undergraduate: Holds a Bachelor’s degree or equivalent from a recognized higher education institution.\n",
    "            - Not Applicable (if none apply, e.g., abstract entities, non-human beings, deities, or supernatural beings).\n",
    "\n",
    "        - Era: \n",
    "            - Historical (before 1800)\n",
    "            - Modern (after 1800)\n",
    "\n",
    "        - Ethnicity: \n",
    "            - African: Includes Sub-Saharan Africans (e.g., Nigerians, Kenyans) and North Africans (e.g., Egyptians, Moroccans).\n",
    "            - American: Includes Native Americans, First Nations (Canada), and Indigenous peoples of Central and South America, as well as those of European, African, Asian, and other ancestries who have historically formed distinct cultural identities within the region.\n",
    "            - Asian: Includes East Asians (e.g., Chinese, Japanese, Koreans), South Asians (e.g., Indians, Pakistanis, Bangladeshis), and Southeast Asians (e.g., Indonesians, Vietnamese, Thais).\n",
    "            - Australian: Indigenous peoples of Australia with distinct cultural and linguistic heritage.\n",
    "            - European: Includes Western Europeans (e.g., French, Germans), Eastern Europeans (e.g., Russians, Poles), and Southern Europeans (e.g., Italians, Greeks).\n",
    "            - Latino or Hispanic: Includes people from Latin America and the Caribbean, encompassing diverse ethnic backgrounds (e.g., Mexicans, Brazilians, Cubans).\n",
    "            - Middle Eastern and Central Asian: Includes Arabs, Persians (Iranians), Turks, Kurds, and ethnicities from Central Asia (e.g., Uzbeks, Kazakhs).\n",
    "            - Mixed or Multiracial: Includes individuals with ancestry from multiple ethnic backgrounds.\n",
    "            - Not Applicable (if none of the above apply, e.g., abstract entities)\n",
    "            - Unknown (if none of the above apply)\n",
    "\n",
    "        - Entity Existence Type: \n",
    "            - Animal & Fictional character\n",
    "            - Animal & Mythological character\n",
    "            - Animal & Real\n",
    "            - God\n",
    "            - Human & Fictional character\n",
    "            - Human & Mythological character\n",
    "            - Human & Real\n",
    "            - Other Being\n",
    "\n",
    "        - Fame (Sentiment associated with the entity): \n",
    "            - Controversial\n",
    "            - Famous\n",
    "            - Infamous\n",
    "\n",
    "        - Gender: \n",
    "            - Boy/Man\n",
    "            - Girl/Woman\n",
    "            - Gender Neutral\n",
    "            - Non-Binary\n",
    "            - Transgender\n",
    "            - Not Applicable (if none apply, e.g., abstract entities)\n",
    "\n",
    "        - Life Status: \n",
    "            - Alive\n",
    "            - Dead\n",
    "            - Not Applicable (for abstract entities like concepts or gods)\n",
    "\n",
    "        - Nationality: The native country of the entity (e.g., India, Bangladesh, France) if applicable, else Unknown.\n",
    "\n",
    "        - Origin-of-Culture: \n",
    "            - Exotic (from a different demography as compared to the speakers of {language} language)\n",
    "            - Native (same demography as the speakers of {language} language)\n",
    "\n",
    "        - Pronoun/Verb in Article Text: Identify the type of pronouns/verbs used in the article text with respect to {title} and select one of the following option:\n",
    "            - Honorific: Select this option if most of the pronouns and/or verbs used in the article are formal, respectful, or honorific.\n",
    "            - Non-Honorific: Select this option if most of the pronouns and/or verbs used in the article are informal, casual, or non-honorific.\n",
    "            - Not Applicable: Select this option if the article does not contain any pronouns or verbs at all that can help classify it under either of the above two categories(honorific or non-honorific).\n",
    "\n",
    "            If the article has mixed usage of honorific and non-honorific pronouns/verbs, list down all the pronouns/verbs used for {title} and classify the ones having the majority.  \n",
    "\n",
    "        - Religion: \n",
    "            - Atheism\n",
    "            - Buddhism\n",
    "            - Christianity\n",
    "            - Hinduism\n",
    "            - Indigenous or Tribal Religions (e.g., Native American spirituality, African traditional religions, Aboriginal beliefs)\n",
    "            - Islam\n",
    "            - Jainism\n",
    "            - Judaism\n",
    "            - Sikhism\n",
    "            - Not Applicable (if none apply, e.g., abstract entities)\n",
    "\n",
    "        - Role: Choose the best fitting category based on the following (use your judgment if the entity fits multiple categories):\n",
    "            - Activists and Reformers (e.g., civil rights, environmental, social activists)\n",
    "            - Arts and Culture\n",
    "            - Business and Economy\n",
    "            - Criminals (e.g., criminal, terrorist, outlaw, fraudster)\n",
    "            - Deity\n",
    "            - Education and Academia\n",
    "            - Entertainment (use this over Arts and Culture if the entity is primarily involved in entertainment)\n",
    "            - Infamous/Controversial Activists (e.g., controversial or notorious figures in activism or leadership)\n",
    "            - Law and Justice\n",
    "            - Literature and Philosophy\n",
    "            - Media and Journalism\n",
    "            - Medicine and Healthcare\n",
    "            - Military\n",
    "            - Politics and Governance\n",
    "            - Public Service\n",
    "            - Religion and Spirituality\n",
    "            - Royalty and Nobility\n",
    "            - Science and Technology\n",
    "            - Sports\n",
    "            - Not Applicable (if none of the above apply)\n",
    "\n",
    "        - Sex: \n",
    "            - Female\n",
    "            - Male\n",
    "            - Not Applicable (if none apply, e.g., abstract entities or non-living beings)\n",
    "\n",
    "        - Sexual Orientation: \n",
    "            - Bisexual\n",
    "            - Heterosexual\n",
    "            - Homosexual\n",
    "            - Not Applicable (if none apply, e.g., abstract entities)\n",
    "\n",
    "        Output Format:\n",
    "\n",
    "        ONLY provide your answers in dictionary format, where the keys are the feature names, and the values correspond only from the options provided above. Do NOT include any additional text besides the dictionary. Example format:\n",
    "\n",
    "        {{\n",
    "        'Age Group': 'Adult',\n",
    "        'Caste': 'Marginalized Groups',\n",
    "        'Count': 'Singular',\n",
    "        'Highest Educational Qualification': 'Doctoral',\n",
    "        'Entity Existence Type': 'Human',\n",
    "        'Era': 'Modern',\n",
    "        'Ethnicity': 'Asian',\n",
    "        'Fame': 'Famous',\n",
    "        'Gender': 'Boy/Man',\n",
    "        'Life Status': 'Dead',\n",
    "        'Nationality': 'India',\n",
    "        'Origin-of-Culture': 'Native',\n",
    "        'Pronoun/Verb in Article Text': 'Honorific',\n",
    "        'Religion': 'Hinduism',\n",
    "        'Role': 'Politics and Governance',\n",
    "        'Sex': 'Male',\n",
    "        'Sexual Orientation': 'Heterosexual',\n",
    "        }}\n",
    "        \"\"\"\n",
    "        }\n",
    "        ]\n",
    "    \n",
    "    # print(messages[1][\"content\"])\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "      model=deployment,\n",
    "      messages = messages,\n",
    "      temperature=0,\n",
    "      max_tokens=256,\n",
    "      top_p=1\n",
    "    ) \n",
    "    \n",
    "    # print(messages[1][\"content\"])\n",
    "    \n",
    "    # response = client.messages.create(\n",
    "    # model=\"claude-3-5-sonnet-20241022\",\n",
    "    # max_tokens=1024,\n",
    "    # messages=messages,\n",
    "    # )\n",
    "    \n",
    "    out = response\n",
    "    \n",
    "    return out, messages[1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "\n",
    "def get_wikipedia_categories(page_title, language):\n",
    "    # Decode back to original representation\n",
    "    page_title = urllib.parse.unquote(page_title)\n",
    "\n",
    "    # print(decoded_text)\n",
    "    url = f\"https://{language}.wikipedia.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"query\",\n",
    "            \"prop\": \"categories\",\n",
    "            \"exintro\": True,\n",
    "            \"explaintext\": True,\n",
    "            \"cllimit\": \"max\",  # Fetch all categories\n",
    "            \"redirects\": 1,    # Automatically resolve redirects\n",
    "            \"titles\": page_title,\n",
    "            \"format\": \"json\",\n",
    "            \"clshow\": \"hidden\",\n",
    "    }\n",
    "    print(url)\n",
    "    response = requests.get(url, params=params, timeout=60)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Bad request\")\n",
    "        print(response.status_code)\n",
    "        return []\n",
    "\n",
    "    categories = []\n",
    "\n",
    "    data = response.json()\n",
    "    # print(data)\n",
    "    pages = data[\"query\"][\"pages\"]\n",
    "    print(pages)\n",
    "    for key in pages.keys():\n",
    "        if \"categories\" in pages[key]:\n",
    "            # print(pages[key][\"categories\"][0])\n",
    "            categories.extend([cat[\"title\"] for cat in pages[key][\"categories\"]])\n",
    "            # print(categories)\n",
    "    return categories\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [02:14,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Price for 100 prompts: $0.3738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import urllib.parse\n",
    "\n",
    "# URL-encoded string\n",
    "\n",
    "# Pricing details\n",
    "model_type = \"GPT-4o-2024-1120 Global\"\n",
    "input_price_per_token = 0.0025 / 1000\n",
    "output_price_per_token = 0.001 / 1000\n",
    "# output_file = f\"{csv_lang}.json\"\n",
    "\n",
    "#### Tester\n",
    "output_file = \"test_hi.json\"\n",
    "\n",
    "# Ensure the output file exists or create an empty JSON file\n",
    "if not os.path.exists(output_file):\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump([], f)  # Initialize an empty JSON array\n",
    "\n",
    "# Load existing JSON file if available\n",
    "try:\n",
    "    with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        existing_data = json.load(f)\n",
    "except (json.JSONDecodeError, FileNotFoundError):\n",
    "    existing_data = []  # If the file is corrupt or missing, start fresh\n",
    "    \n",
    "existing_titles = {entry[\"title\"] for entry in existing_data}\n",
    "print(len(existing_titles))\n",
    "# Convert existing data into a dictionary for quick lookup (title + language as key)\n",
    "existing_entries = {(entry[\"title\"], entry[\"language\"]) for entry in existing_data}\n",
    "\n",
    "# Initialize total price counter\n",
    "total_price = 0\n",
    "\n",
    "lang_id_mapper = {\n",
    "    \"hi\" : \"Hindi\",\n",
    "    \"ko\" : \"Korean\",\n",
    "    \"ja\" : \"Japanese\",\n",
    "    \"bn\" : \"Bengali\",\n",
    "    \"mr\" : \"Marathi\",\n",
    "    \"en\" : \"English\",\n",
    "    \"th\" : \"Thai\",\n",
    "    \"jv\" : \"Javanese\",\n",
    "    \"ne\" : \"Nepali\", \n",
    "    \"ta\" : \"Tamil\",\n",
    "    \"ur\" : \"Urdu\",\n",
    "    \"bpy\" : \"Bishnupriya Manipuri\"\n",
    "}\n",
    "\n",
    "def calculate_price(prompt_tokens, completion_tokens):\n",
    "    \"\"\"Calculate the price based on token usage.\"\"\"\n",
    "    return (prompt_tokens * input_price_per_token) + (completion_tokens * output_price_per_token)\n",
    "\n",
    "for i, row in tqdm(inference_df.iterrows()):\n",
    "    en_category = row[\"en_categories\"]\n",
    "    # en_category = \"|\".join(en_categories)\n",
    "    # print(en_category)\n",
    "    col = \"hi_intro\"\n",
    "    # for col in inference_df.columns:\n",
    "        \n",
    "        # if \"intro\" in col and \"en\" not in col and csv_lang in col: \n",
    "    # if pd.isna(row[col]) or row[col] == \"\" or not row[col] : \n",
    "    #     continue\n",
    "        \n",
    "    title_language_pair = (row[\"title\"], col.split(\"_\")[0])\n",
    "\n",
    "    # Skip if the data already exists\n",
    "    if title_language_pair in existing_entries:\n",
    "        # print(f\"[INFO] Skipping {title_language_pair} (Already Exists)\")\n",
    "        continue\n",
    "    \n",
    "    lang_str = col.split(\"_\")[0]\n",
    "    # lang_category = row[f\"{lang_str}_categories\"]\n",
    "    # lang_category = \"|\".join(lang_categories)\n",
    "    # print(lang_category)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Generate API response\n",
    "    outcome, prompt = generate_output(row[\"title\"], row[col], en_category, \"\", lang_id_mapper[lang_str], model_type)\n",
    "\n",
    "    # Extract token usage\n",
    "    prompt_tokens = outcome.usage.prompt_tokens\n",
    "    completion_tokens = outcome.usage.completion_tokens\n",
    "\n",
    "    # Calculate price\n",
    "    single_price = calculate_price(prompt_tokens, completion_tokens)\n",
    "    total_price += single_price\n",
    "\n",
    "    # Prepare JSON output\n",
    "    json_out = postprocess(outcome.choices[0].message.content)\n",
    "    json_out[\"title\"] = row[\"title\"]\n",
    "    json_out[\"article_text\"] = row[col]\n",
    "    json_out[\"categories\"] = en_category\n",
    "    json_out[\"language_categories\"] = \"\"\n",
    "    json_out[\"language\"] = lang_str\n",
    "    json_out[\"price\"] = single_price\n",
    "    json_out[\"prompt\"] = prompt\n",
    "\n",
    "    # Append new result to file immediately\n",
    "    with open(output_file, \"r+\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            data = json.load(f)  # Load existing data\n",
    "        except json.JSONDecodeError:\n",
    "            data = []  # If file is empty/corrupt, start fresh\n",
    "\n",
    "        data.append(json_out)  # Append new data\n",
    "        \n",
    "        f.seek(0)  # Move cursor to start of file before writing\n",
    "        json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "        f.truncate()  # Remove extra trailing content if any\n",
    "\n",
    "    # Mark as processed\n",
    "    existing_entries.add(title_language_pair)\n",
    "    # print(f\"[INFO] Saved: {title_language_pair}\")\n",
    "            \n",
    "\n",
    "print(\"Total Price for {} prompts: ${:.4f}\".format(len(existing_entries), total_price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"r+\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            data = json.load(f)  # Load existing data\n",
    "        except json.JSONDecodeError:\n",
    "            data = []  # If file is empty/corrupt, start fresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age Group</th>\n",
       "      <th>Caste</th>\n",
       "      <th>Count</th>\n",
       "      <th>Highest Educational Qualification</th>\n",
       "      <th>Entity Existence Type</th>\n",
       "      <th>Era</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Fame</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Life Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Role</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Sexual Orientation</th>\n",
       "      <th>title</th>\n",
       "      <th>article_text</th>\n",
       "      <th>categories</th>\n",
       "      <th>language_categories</th>\n",
       "      <th>language</th>\n",
       "      <th>price</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Merchant and Artisan Class</td>\n",
       "      <td>Singular</td>\n",
       "      <td>Postgraduate</td>\n",
       "      <td>Human &amp; Real</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Famous</td>\n",
       "      <td>Boy/Man</td>\n",
       "      <td>Alive</td>\n",
       "      <td>...</td>\n",
       "      <td>Politics and Governance</td>\n",
       "      <td>Male</td>\n",
       "      <td>Heterosexual</td>\n",
       "      <td>Rishi Sunak</td>\n",
       "      <td>ऋषि सुनक (जन्म 12 मई 1980) भारतीय मूल के ब्रिट...</td>\n",
       "      <td>Category:1980 births|Category:21st-century pri...</td>\n",
       "      <td></td>\n",
       "      <td>hi</td>\n",
       "      <td>0.007096</td>\n",
       "      <td>We need your help to specify the usage of thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singular</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Human &amp; Real</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Famous</td>\n",
       "      <td>Girl/Woman</td>\n",
       "      <td>Alive</td>\n",
       "      <td>...</td>\n",
       "      <td>Politics and Governance</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Bidya Devi Bhandari</td>\n",
       "      <td>विद्या देवी भंडारी (नेपाली: विद्यादेवी भण्डारी...</td>\n",
       "      <td>Category:1961 births|Category:21st-century Nep...</td>\n",
       "      <td></td>\n",
       "      <td>hi</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>We need your help to specify the usage of thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Juvenile</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singular</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Human &amp; Real</td>\n",
       "      <td>Modern</td>\n",
       "      <td>European</td>\n",
       "      <td>Famous</td>\n",
       "      <td>Girl/Woman</td>\n",
       "      <td>Alive</td>\n",
       "      <td>...</td>\n",
       "      <td>Activists and Reformers</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Greta Thunberg</td>\n",
       "      <td>ग्रेटा थनबर्ग (ग्रेटा टिनटिन एलोनोरा एर्नमन थन...</td>\n",
       "      <td>Category:2003 births|Category:21st-century Swe...</td>\n",
       "      <td></td>\n",
       "      <td>hi</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>We need your help to specify the usage of thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singular</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>God</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Famous</td>\n",
       "      <td>Girl/Woman</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>...</td>\n",
       "      <td>Deity</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Durga</td>\n",
       "      <td>दुर्गा या आदिशक्ति हिन्दुओं की प्रमुख देवी मान...</td>\n",
       "      <td>Category:All articles with unsourced statement...</td>\n",
       "      <td></td>\n",
       "      <td>hi</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>We need your help to specify the usage of thir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Singular</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>God</td>\n",
       "      <td>Historical</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Famous</td>\n",
       "      <td>Girl/Woman</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>...</td>\n",
       "      <td>Deity</td>\n",
       "      <td>Female</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Saraswati</td>\n",
       "      <td>सरस्वती हिन्दू धर्म की प्रमुख वैदिक एवं पौराणि...</td>\n",
       "      <td>Category:All articles covered by WikiProject W...</td>\n",
       "      <td></td>\n",
       "      <td>hi</td>\n",
       "      <td>0.009890</td>\n",
       "      <td>We need your help to specify the usage of thir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age Group                       Caste     Count  \\\n",
       "0           Adult  Merchant and Artisan Class  Singular   \n",
       "1           Adult              Not Applicable  Singular   \n",
       "2        Juvenile              Not Applicable  Singular   \n",
       "3  Not Applicable              Not Applicable  Singular   \n",
       "4  Not Applicable              Not Applicable  Singular   \n",
       "\n",
       "  Highest Educational Qualification Entity Existence Type         Era  \\\n",
       "0                      Postgraduate          Human & Real      Modern   \n",
       "1                    Not Applicable          Human & Real      Modern   \n",
       "2                    Not Applicable          Human & Real      Modern   \n",
       "3                    Not Applicable                   God  Historical   \n",
       "4                    Not Applicable                   God  Historical   \n",
       "\n",
       "        Ethnicity    Fame      Gender     Life Status  ...  \\\n",
       "0           Asian  Famous     Boy/Man           Alive  ...   \n",
       "1           Asian  Famous  Girl/Woman           Alive  ...   \n",
       "2        European  Famous  Girl/Woman           Alive  ...   \n",
       "3  Not Applicable  Famous  Girl/Woman  Not Applicable  ...   \n",
       "4  Not Applicable  Famous  Girl/Woman  Not Applicable  ...   \n",
       "\n",
       "                      Role     Sex Sexual Orientation                title  \\\n",
       "0  Politics and Governance    Male       Heterosexual          Rishi Sunak   \n",
       "1  Politics and Governance  Female     Not Applicable  Bidya Devi Bhandari   \n",
       "2  Activists and Reformers  Female     Not Applicable       Greta Thunberg   \n",
       "3                    Deity  Female     Not Applicable                Durga   \n",
       "4                    Deity  Female     Not Applicable            Saraswati   \n",
       "\n",
       "                                        article_text  \\\n",
       "0  ऋषि सुनक (जन्म 12 मई 1980) भारतीय मूल के ब्रिट...   \n",
       "1  विद्या देवी भंडारी (नेपाली: विद्यादेवी भण्डारी...   \n",
       "2  ग्रेटा थनबर्ग (ग्रेटा टिनटिन एलोनोरा एर्नमन थन...   \n",
       "3  दुर्गा या आदिशक्ति हिन्दुओं की प्रमुख देवी मान...   \n",
       "4  सरस्वती हिन्दू धर्म की प्रमुख वैदिक एवं पौराणि...   \n",
       "\n",
       "                                          categories language_categories  \\\n",
       "0  Category:1980 births|Category:21st-century pri...                       \n",
       "1  Category:1961 births|Category:21st-century Nep...                       \n",
       "2  Category:2003 births|Category:21st-century Swe...                       \n",
       "3  Category:All articles with unsourced statement...                       \n",
       "4  Category:All articles covered by WikiProject W...                       \n",
       "\n",
       "  language     price                                             prompt  \n",
       "0       hi  0.007096  We need your help to specify the usage of thir...  \n",
       "1       hi  0.006175  We need your help to specify the usage of thir...  \n",
       "2       hi  0.006941  We need your help to specify the usage of thir...  \n",
       "3       hi  0.008840  We need your help to specify the usage of thir...  \n",
       "4       hi  0.009890  We need your help to specify the usage of thir...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ग्रेटा थनबर्ग (ग्रेटा टिनटिन एलोनोरा एर्नमन थनबर्ग) (जन्म 3 जनवरी 2003) स्वीडन की एक पर्यावरण कार्यकर्ता हैं जिनके पर्यावरण आंदोलन/आन्दोलन को अंतरराष्ट्रीय/अन्तरराष्ट्रीय ख्याति मिली है। स्वीडन की इस किशोरी के आंदोलनों/आन्दोलनों के फलस्वरूप विश्व के नेता अब जलवायु परिवर्तन पर कार्य करने के लिए विवश हुए हैं। अगस्त 2018 में, 15 की उम्र में, थनबर्ग ने स्कूल से समय निकालकर हाथ में स्वीडन की भाषा में \"Skolstrejk för klimatet \" ( जलवायु के लिए स्कूलबन्दी (स्कूलबंदी)) लिखी तख्ती लिए स्वीडन की संसद के बाहर प्रदर्शन करना शुरू किया। 11 दिसम्बर 2019 को इन्हे \\'टाइम पर्सन ऑफ़ द ईयर\\' पुरस्कार प्रदान किया गया। ग्रेटा अपने सीधे-साधे शब्दों में बात करने के लिए भी जानी जातीं हैं। अपनी सार्वजनिक सभाओं में और राजनीतिक नेताओं के साथ वार्ता में वे जलवायु संकट पर तुरन्त (तुरंत) कार्वाई करने का आग्रह करतीं हैं।'"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data.iloc[2][\"article_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age Group                                                                     Juvenile\n",
       "Caste                                                                   Not Applicable\n",
       "Count                                                                         Singular\n",
       "Highest Educational Qualification                                       Not Applicable\n",
       "Entity Existence Type                                                     Human & Real\n",
       "Era                                                                             Modern\n",
       "Ethnicity                                                                     European\n",
       "Fame                                                                            Famous\n",
       "Gender                                                                      Girl/Woman\n",
       "Life Status                                                                      Alive\n",
       "Nationality                                                                     Sweden\n",
       "Origin-of-Culture                                                               Exotic\n",
       "Pronoun/Verb in Article Text                                                 Honorific\n",
       "Religion                                                                Not Applicable\n",
       "Role                                                           Activists and Reformers\n",
       "Sex                                                                             Female\n",
       "Sexual Orientation                                                      Not Applicable\n",
       "title                                                                   Greta Thunberg\n",
       "article_text                         ग्रेटा थनबर्ग (ग्रेटा टिनटिन एलोनोरा एर्नमन थन...\n",
       "categories                           Category:2003 births|Category:21st-century Swe...\n",
       "language_categories                                                                   \n",
       "language                                                                            hi\n",
       "price                                                                         0.006941\n",
       "prompt                               We need your help to specify the usage of thir...\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotated_data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data.to_csv(\"llm_annotation_v2/hi_10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_data = pd.read_csv(\"hi_annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Pronoun/Verb in Article Text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Pronoun/Verb in Article Text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 29\u001b[0m\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     27\u001b[0m df \u001b[38;5;241m=\u001b[39m annotated_data\n\u001b[0;32m---> 29\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhonorific\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerge_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m final_df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPronoun/Verb in Article text\u001b[39m\u001b[38;5;124m\"\u001b[39m], axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     33\u001b[0m final_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWiki_annotations_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcsv_lang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[83], line 10\u001b[0m, in \u001b[0;36mmerge_columns\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      7\u001b[0m col1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPronoun/Verb in Article Text\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m col2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPronoun/Verb in Article text\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol1\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[col1]) : \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m row[col2]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row[col2] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[col2]) : \n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/Atharva/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Pronoun/Verb in Article Text'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def merge_columns(row) : \n",
    "    col1 = \"Pronoun/Verb in Article Text\"\n",
    "    col2 = \"Pronoun/Verb in Article text\"\n",
    "    \n",
    "    if row[col1] == None or pd.isna(row[col1]) : \n",
    "        return row[col2]\n",
    "    \n",
    "    if row[col2] == None or pd.isna(row[col2]) : \n",
    "        return row[col1]\n",
    "    \n",
    "    return row[col1] + row[col2]\n",
    "\n",
    "# # Load JSON data from file\n",
    "output_file = \"output.json\"\n",
    "\n",
    "with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract relevant data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = annotated_data\n",
    "\n",
    "df[\"honorific\"] = df.apply(merge_columns, axis=1)\n",
    "\n",
    "final_df = df.drop([\"Pronoun/Verb in Article text\"], axis = 1)\n",
    "\n",
    "final_df.to_csv(f\"Wiki_annotations_{csv_lang}.csv\")\n",
    "\n",
    "# Ensure required columns exist\n",
    "if \"language\" not in df.columns: \n",
    "    raise ValueError(\"Missing required columns in JSON file.\")\n",
    "\n",
    "print(df.info())\n",
    "\n",
    "# Convert 'honorific' field to boolean (assuming values like 'yes'/'no' or True/False)\n",
    "df[\"honorific\"] = df[\"honorific\"].astype(str).str.lower().map({\"Honorific\": 1, \"honorific\": 1, \"non-honorific\": 0, \"Non-Honorific\": 0})\n",
    "\n",
    "# Aggregate counts per language\n",
    "summary = df.groupby(\"language\")[\"honorific\"].agg([\"sum\", \"count\"])\n",
    "summary.rename(columns={\"sum\": \"honorific_count\", \"count\": \"total_count\"}, inplace=True)\n",
    "\n",
    "# Calculate non-honorific count and percentages\n",
    "summary[\"non_honorific_count\"] = summary[\"total_count\"] - summary[\"honorific_count\"]\n",
    "summary[\"honorific_percentage\"] = (summary[\"honorific_count\"] / summary[\"total_count\"]) * 100\n",
    "summary[\"non_honorific_percentage\"] = 100 - summary[\"honorific_percentage\"]\n",
    "\n",
    "# Sorting by honorific percentage for better visualization\n",
    "summary = summary.sort_values(by=\"honorific_percentage\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "languages = summary.index\n",
    "honorific_counts = summary[\"honorific_count\"]\n",
    "non_honorific_counts = summary[\"non_honorific_count\"]\n",
    "honorific_percentages = summary[\"honorific_percentage\"]\n",
    "\n",
    "x = np.arange(len(languages))  # X-axis positions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Stacked bar plot\n",
    "bars1 = ax.bar(x, non_honorific_counts, label=\"Non-Honorific\", color=\"lightblue\")\n",
    "bars2 = ax.bar(x, honorific_counts, bottom=non_honorific_counts, label=\"Honorific\", color=\"orange\")\n",
    "\n",
    "# Labels and Titles\n",
    "ax.set_xlabel(\"Language\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Honorific vs. Non-Honorific Mentions by Language\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(languages, rotation=45, ha=\"right\")\n",
    "ax.legend()\n",
    "\n",
    "# Adding percentage labels on bars\n",
    "for i, (bar1, bar2) in enumerate(zip(bars1, bars2)):\n",
    "    height1 = bar1.get_height()\n",
    "    height2 = bar2.get_height()\n",
    "    total_height = height1 + height2\n",
    "\n",
    "    # Show honorific percentage on top\n",
    "    ax.text(bar1.get_x() + bar1.get_width() / 2, total_height + 1, f\"{honorific_percentages.iloc[i]:.1f}%\", \n",
    "            ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the table to get one column per language\n",
    "df_pivot = df.pivot_table(index=\"title\", columns=\"language\", values=\"honorific\", aggfunc=\"max\", fill_value=0)\n",
    "\n",
    "# Reset index to turn title back into a column\n",
    "df_pivot.reset_index(inplace=True)\n",
    "\n",
    "df_pivot.to_csv(\"pivot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df.drop([\"Pronoun/Verb in Wiki Article\"], axis=1)\n",
    "\n",
    "lr_df = df.copy()\n",
    "lr_df = lr_df.drop([\"article_text\", \"categories\", \"title\", \"Entity\"], axis=1)\n",
    "lr_df = lr_df[lr_df[\"language\"].str.contains(\"ja\")].reset_index()\n",
    "\n",
    "encoders = {}\n",
    "\n",
    "for col in lr_df.columns :     \n",
    "    col_encoder = LabelEncoder()\n",
    "    lr_df[col] = col_encoder.fit_transform(lr_df[col])\n",
    "    encoders[col] = col_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = \"Era\"\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "inverse = encoders[column].inverse_transform(lr_df[\"Era\"])\n",
    "\n",
    "for i, row in lr_df.iterrows() : \n",
    "    val = row[column]\n",
    "    \n",
    "    if val not in mapping : \n",
    "        mapping[val] = inverse[i]\n",
    "        \n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(lr_df.drop([\"language\", \"honorific\", \"Pronoun/Verb in Wiki Article\"], axis=1), lr_df[\"honorific\"])\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "print(lr.coef_)\n",
    "\n",
    "print(sum((y_pred-y_test)2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(lr_df.drop([\"language\", \"honorific\", \"Pronoun/Verb in Wiki Article\"], axis=1), lr_df[\"honorific\"])\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "print(lr.coef_)\n",
    "\n",
    "print(classification_report(y_pred=y_pred, y_true=y_test))\n",
    "print(lr_df.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
